\newpage


\begin{abstract}
Исследуется проблема понижения сложности аппроксимирующих моделей с целью повышения их интерпретируемости.
В рамках данного исследования рассматриваются методы, которые используют экспертную информацию о данных с целью получения простых, более интерпретируемых моделей.
Предлагаются методы, основанные на дистилляции моделей глубокого обучения, где модель учителя рассматривается в качестве эксперта.
Также предлагаются методы основанные на экспертном описании задачи, что позволяет строить специальные признаковые описания объектов.
Теоретические результаты анализируются в вычислительном эксперименте на синтетических выборках и реальных данных.
В качестве реальных данных рассматривается популярные выборки, такие как MNIST, FashionMNIST и Twitter Sentiment Analysis.


\smallskip
\textit{Ключевые слова}: выбор модели; байесовский вывод; дистилляция модели; локальные преобразования; преобразования вероятностных пространств; релевантноть параметров.
\end{abstract}

